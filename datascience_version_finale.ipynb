{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8384261,"sourceType":"datasetVersion","datasetId":4986395}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Présentation générale de l'ensemble de données\n\n___\nPlongeons dans le fascinant paysage des données criminelles des États-Unis avec ce dataset riche et complexe. \n\nAvec pas moins de 127 attributs sélectionnés, chaque ligne de ce tableau offre une fenêtre sur la dynamique sociale et policière des communautés américaines. Ces variables, judicieusement choisies pour leur potentiel prédictif dans le domaine de la criminalité, englobent un vaste éventail de facteurs, allant de la densité urbaine au revenu familial médian, en passant par la situation sociale des habitants. \n\nLe cœur de cette compilation réside dans la variable \"**Crimes violents par habitant**\", calculée minutieusement à partir de la population et de la somme des crimes considérés comme violents aux États-Unis. \n\nCependant, ce tableau n'est pas simplement une collection de chiffres bruts. Chaque donnée numérique a été normalisée dans une plage décimale allant de 0 à 1, préservant ainsi les nuances des ratios internes tout en permettant des comparaisons significatives. \n\nToutefois, derrière cette richesse de données, des défis ont été relevés, des controverses concernant le comptage des viols aux absences de certaines communautés dans les ensembles de données. \n\nMalgré ces limites, plongeons dans ce tableau, explorons les profondeurs de la criminalité américaine et découvrons les histoires que ces données peuvent raconter ✨\n___","metadata":{}},{"cell_type":"markdown","source":"# Notre problèmatique\n\n**Prédiction du taux de criminalité violente** \n\nEn utilisant les caractéristiques **socio-économiques et démographiques** des crimes commis aux Etats-Unis, nous allons essayer de prédire le taux de criminalité violente dans différents états.","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-05T22:24:57.266116Z","iopub.execute_input":"2024-06-05T22:24:57.266559Z","iopub.status.idle":"2024-06-05T22:24:57.284516Z","shell.execute_reply.started":"2024-06-05T22:24:57.266526Z","shell.execute_reply":"2024-06-05T22:24:57.283333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I - Analyse des données du dataset","metadata":{}},{"cell_type":"markdown","source":"Dans le but de comprendre nos données , on a effectué certains tests liés aux élements qu'on a vu en classe afin de pouvoir lire, explorer et déduire des conclusions.\n\nDans un premier temps, nous allons renommer les colonnes de notre tableau avec des noms significatifs, étant donné qu'il s'agit uniquement de chiffres bruts à l'état initial du dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:24:58.835829Z","iopub.execute_input":"2024-06-05T22:24:58.836252Z","iopub.status.idle":"2024-06-05T22:24:58.841450Z","shell.execute_reply.started":"2024-06-05T22:24:58.836218Z","shell.execute_reply":"2024-06-05T22:24:58.839993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Charger le fichier communities.data dans un DataFrame\ncommunities_and_crime = pd.read_csv('/kaggle/input/communities-and-crime/communities+and+crime/communities.data')\n\n# Redéfinition des noms de colonnes\ncommunities_and_crime.columns=['state','county', 'community','communityname','fold','population', 'householdsize','racepctBlack','racepctWhite','racepctAsian',\n                               'racepctHisp','agePct12t21','agePct12t29','agePct16t24','agePct65up','numbUrban','pctUrban','medIncome', 'pctWWage', 'pctWFarmSelf',\n                               'pctWInvInc', 'pctWSocSec', 'pctWPubAsst','pctWRetire', 'medFamInc', 'perCapInc','whitePerCap','blackPerCap','indianPerCap','AsianPerCap',\n                               'OtherPerCap','HispPerCap','NumUnderPov', 'PctPopUnderPov','PctLess9thGrade','PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu', \n                               'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr','FemalePctDiv','TotalPctDiv','PersPerFam', 'PctFam2Par', 'PctKids2Par',\n                               'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig','PctImmigRecent','PctImmigRec5','PctImmigRec8', \n                               'PctImmigRec10','PctRecentImmig','PctRecImmig5','PctRecImmig8','PctRecImmig10', 'PctSpeakEnglOnly','PctNotSpeakEnglWell','PctLargHouseFam', 'PctLargHouseOccup', 'PersPerOccupHous', \n                               'PersPerOwnOccHous','PersPerRentOccHous', 'PctPersOwnOccup','PctPersDenseHous','PctHousLess3BR','MedNumBR','HousVacant','PctHousOccup','PctHousOwnOcc','PctVacantBoarded',\n                               'PctVacMore6Mos', 'MedYrHousBuilt','PctHousNoPhone','PctWOFullPlumb','OwnOccLowQuart','OwnOccMedVal','OwnOccHiQuart','RentLowQ','RentMedian','RentHighQ',\n                               'MedRent','MedRentPctHousInc','MedOwnCostPctInc','MedOwnCostPctIncNoMtg','NumInShelters','NumStreet','PctForeignBorn','PctBornSameState','PctSameHouse85','PctSameCity85',\n                               'PctSameState85','LemasSwornFT','LemasSwFTPerPop','LemasSwFTFieldOps','LemasSwFTFieldPerPop','LemasTotalReq','LemasTotReqPerPop','PolicReqPerOffic','PolicPerPop','RacialMatchCommPol',\n                               'PctPolicWhite','PctPolicBlack','PctPolicHisp','PctPolicAsian','PctPolicMinor','OfficAssgnDrugUnits','NumKindsDrugsSeiz','PolicAveOTWorked','LandArea','PopDens',\n                               'PctUsePubTrans','PolicCars','PolicOperBudg','LemasPctPolicOnPatr','LemasGangUnitDeploy','LemasPctOfficDrugUn','PolicBudgPerPop','ViolentCrimesPerPop']\n\n# Afficher le nombre de lignes (crimes) commis\nprint(\"Nombre de crimes dans le dataset (lignes): \\n ->\", len(communities_and_crime))\nprint(\"=========================================\")\n\n# Afficher les noms des colonnes, qui sont les \"features\"\nprint(\"Nombre de colonnes : \\n ->\", len(communities_and_crime.columns))\nprint(\"=========================================\")\nprint(\"Noms des features du dataset :\\n\\n\", communities_and_crime.columns)\n\n\nprint(\"----------------------------------------------------------------------------------\")\n# Afficher un aperçu des données avec des valeurs manquantes \nprint(communities_and_crime.head())\n\n####################################################\n# Remplacer les '?' par NaN\ncommunities_and_crime.replace('?', \"NaN\", inplace=True)\n####################################################\n\nprint(\"----------------------------------------------------------------------------------\")\n# Afficher un aperçu des données après remplacement des valeurs manquantes \nprint(communities_and_crime.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:24:59.266422Z","iopub.execute_input":"2024-06-05T22:24:59.266794Z","iopub.status.idle":"2024-06-05T22:24:59.356391Z","shell.execute_reply.started":"2024-06-05T22:24:59.266766Z","shell.execute_reply":"2024-06-05T22:24:59.355159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> * Nous remarquons donc que chaque **ligne** de notre dataset représente **une communauté (ou une ville)** aux États-Unis.\n> * Par exemple, pour le première ville, on peut voir la moyenne du nombre de personnes d'un foyer, les origines raciales de sa population (en pourcentage), leurs tranches d'âge...etc.\n> * D'apès la description du dataset sur \n[https://archive.ics.uci.edu/dataset/183/communities+and+crime](http://archive.ics.uci.edu/dataset/183/communities+and+crime), les 127 premières colonnes représentent des **features**, tandis que la dernière colonne (**ViolentCrimesPerPop**) représente la **target**.","metadata":{}},{"cell_type":"markdown","source":"___\nDans le contexte de notre dataset, les criminalités violentes représentent : *les meurtres, les viols, les vols et les agressions.*\n\nNous avons ainsi la colonne target **ViolentCrimesPerPop** qui est décrite comme suit : \n\n> *ViolentCrimesPerPop = nombre total de crimes violents par 100K personnes*\n\nDans notre cas, les valeurs sont continues et elles varient entre 0 et 1. \n\nEtant des valeurs pas très variées et pour avoir une meilleure lisibilité des valeurs réelles, nous allons créer une nouvelle colonne nommée **Numeric_ViolentCrimesPerPop** qui va contenir des intervalles de valeurs plutôt que des valeurs discrètes, qui correspondent aux valeurs normalisées de *ViolentCrimesPerPop*.\n___","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n#### Transformer les données continues en intervalles pour mieux voir leur fréquence\n\nintervals = [(0.000, 0.067), (0.067, 0.133), (0.133, 0.200), (0.200, 0.267),\n             (0.267, 0.333), (0.333, 0.400), (0.400, 0.467), (0.467, 0.533),\n             (0.533, 0.600), (0.600, 0.667), (0.667, 0.733), (0.733, 0.800),\n             (0.800, 0.867), (0.867, 0.933), (0.933, 1.000)]\n\nvalues = [(0.000, 0.067), (0.067, 0.133), (0.133, 0.200), (0.200, 0.267),\n             (0.267, 0.333), (0.333, 0.400), (0.400, 0.467), (0.467, 0.533),\n             (0.533, 0.600), (0.600, 0.667), (0.667, 0.733), (0.733, 0.800),\n             (0.800, 0.867), (0.867, 0.933), (0.933, 1.000)]\n\ndef map_values(x):\n    for interval, value in zip(intervals, values):\n        if interval[0] <= x and x <= interval[1]:\n            return value\n        \n#####################################################################################################################\n        \n# Créer une nouvelle colonne avec les valeurs numériques des totaux de crimes violents\ncommunities_and_crime['Numeric_ViolentCrimesPerPop'] = communities_and_crime['ViolentCrimesPerPop'].apply(map_values)\n\n# Afficher les fréquences des intervalles de valeurs pour la colonne \"Numeric_ViolentCrimesPerPop\"\ncount = communities_and_crime.groupby('Numeric_ViolentCrimesPerPop').size().sort_values(ascending=False)\n\n#affichage du résultat\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:05.585407Z","iopub.execute_input":"2024-06-05T22:51:05.585806Z","iopub.status.idle":"2024-06-05T22:51:05.612123Z","shell.execute_reply.started":"2024-06-05T22:51:05.585774Z","shell.execute_reply":"2024-06-05T22:51:05.610608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> En observant la répartition du taux de criminalité dans les données, on constate uque le taux de criminalité aux États-Unis varie considérablement d'une communauté à l'autre. \n> \n> Les intervalles les plus représentés dans le dataset se situent dans la plage **inférieure** du taux de criminalité, avec plus de la moitié des communautés ayant un taux de criminalité compris entre 0 et 0,133. \n> \n> Cependant, d'autres communautés présentent également des taux de criminalité plus élevés, comme en témoigne la présence de valeurs dans les intervalles **supérieurs**, jusqu'à 1,00. \n> \n> Cette diversité suggère l'existence de multiples facteurs **socio-économiques et démographiques** qui influencent le niveau de criminalité dans les différentes régions des États-Unis.","metadata":{}},{"cell_type":"markdown","source":"### **Retrouver les états avec les taux de criminalité les plus élevés**\n\n___\n**Important ⚠️**\n\nDans la description du dataset, on a cette information : \n\n> *US state (by number) - not counted as predictive, but if considered, should be consided nominal*\n\nLes États ne peuvent pas être classés dans un ordre numérique significatif (comme on le ferait avec des nombres), mais ils représentent plutôt des catégories distinctes sans aucune hiérarchie intrinsèque. \n\nAinsi, les États seront traités comme des catégories distinctes sans ordre spécifique.\n___","metadata":{}},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:01.543990Z","iopub.execute_input":"2024-06-05T22:25:01.544544Z","iopub.status.idle":"2024-06-05T22:25:01.552564Z","shell.execute_reply.started":"2024-06-05T22:25:01.544499Z","shell.execute_reply":"2024-06-05T22:25:01.551125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculer la moyenne du taux de criminalité pour chaque état\nstate_crime_means = communities_and_crime.groupby('state')['ViolentCrimesPerPop'].mean().reset_index()\n\n# Trier les états par taux de criminalité moyen pour une meilleure visualisation\nstate_crime_means = state_crime_means.sort_values(by='ViolentCrimesPerPop', ascending=False)\n\n# Créer le graphique à barres\nplt.figure(figsize=(10, 5))\nsns.barplot(x='state', y='ViolentCrimesPerPop', data=state_crime_means, palette='viridis')\n\nplt.xlabel('État')\nplt.ylabel('Moyenne des taux de criminalité violente')\nplt.title('Moyenne des taux de criminalité violente par État')\nplt.xticks(rotation=90)  # Rotation des labels de l'axe x pour une meilleure lisibilité\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:01.719400Z","iopub.execute_input":"2024-06-05T22:25:01.719817Z","iopub.status.idle":"2024-06-05T22:25:02.331616Z","shell.execute_reply.started":"2024-06-05T22:25:01.719783Z","shell.execute_reply":"2024-06-05T22:25:02.330375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___\nPour mieux comprendre les facteurs ainsi que les critères ayant conduit à ces taux de criminalité violente assez élevés, nous allons analyser ces données en **3** catégories : \n \n1. Caractéristiques **démographiques**\n2. Caractéristiques **économiques**\n3. Caractéristiques **sociales**\n\nPour plus de lisibilité, nous allons nous baser sur les **10** états ayant la moyenne de taux de criminialité la plus élevée.\n___","metadata":{}},{"cell_type":"code","source":"# Sélectionner les 10 états avec la moyenne de taux de criminalité la plus élevée\ntop_10_states = state_crime_means.head(10)\n\n# Afficher les résultats sans les index\nprint(top_10_states.to_string(index=False))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:02.333613Z","iopub.execute_input":"2024-06-05T22:25:02.334012Z","iopub.status.idle":"2024-06-05T22:25:02.341878Z","shell.execute_reply.started":"2024-06-05T22:25:02.333981Z","shell.execute_reply":"2024-06-05T22:25:02.340680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### A. Caractéristiques démographiques :\n___\n\nAprès une bonne analyse des colonnes du tableau, nous avons pu identifier ces attributs qui reflètent l'aspect démographique des habitants :\n\n- **population**: La population totale de la communauté.\n\n\n- **householdsize**: La taille moyenne des ménages dans la communauté.\n\n- **racepctBlack**: Le pourcentage de la population qui est afro-américaine.\n- **racepctWhite**: Le pourcentage de la population qui est caucasienne.\n- **racepctAsian**: Le pourcentage de la population qui est d'origine asiatique.\n- **racepctHisp**: Le pourcentage de la population qui est d'origine hispanique.\n\n- **agePct12t21**: Le pourcentage de la population âgée de 12 à 21 ans.\n- **agePct12t29**: Le pourcentage de la population âgée de 12 à 29 ans.\n- **agePct16t24**: Le pourcentage de la population âgée de 16 à 24 ans.\n- **agePct65up**: Le pourcentage de la population âgée de 65 ans et plus.\n\n- **numbUrban**: Le nombre de personnes vivant dans des zones urbaines.\n- **pctUrban**: Le pourcentage de la population vivant dans des zones urbaines.\n---\nEn vue du nombre important de ces caractéristiques, nous allons procéder au *Feature Engineering* pour essayer de créer des features plus simples et facile à utiliser.\n\nVoici donc quelques nouvelles features que l'on pourrait créer :\n\n> **Indice de jeunesse (youthIndex):**\n> \n> Un indice combinant les pourcentages de la population âgée de 12 à 21 ans, de 12 à 29 ans et de 16 à 24 ans. \n> Cela pourrait refléter le degré de jeunesse de la population.\n\n\n> **Ratio de diversité ethnique (ethnicDiversityRatio)**:\n>\n> Un indice de la diversité ethnique de la communauté, calculé en mesurant la variance des pourcentages de chaque groupe ethnique. \n> Plus la valeur est élevée, plus la diversité ethnique est grande.\n\n","metadata":{}},{"cell_type":"code","source":"# Créer la colonne youthIndex\ncommunities_and_crime['youthIndex'] = (communities_and_crime['agePct12t21'] + communities_and_crime['agePct12t29'] + communities_and_crime['agePct16t24']) / 3\n\n# Calculer la variance des pourcentages ethniques\nethnic_columns = ['racepctBlack', 'racepctWhite', 'racepctAsian', 'racepctHisp']\ncommunities_and_crime['ethnicDiversityRatio'] = communities_and_crime[ethnic_columns].var(axis=1)\n\n# Afficher les premières lignes du dataset avec les nouvelles features\nprint(communities_and_crime[['youthIndex', 'ethnicDiversityRatio']].head())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:02.381113Z","iopub.execute_input":"2024-06-05T22:25:02.381649Z","iopub.status.idle":"2024-06-05T22:25:02.396810Z","shell.execute_reply.started":"2024-06-05T22:25:02.381610Z","shell.execute_reply":"2024-06-05T22:25:02.395477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sélectionner les 10 premiers états\ntop_10_states = state_crime_means.head(10)['state']\n\n# Sélectionner les colonnes à afficher\ncolumns_to_plot = ['householdsize', 'numbUrban', 'youthIndex', 'ethnicDiversityRatio']\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 6))\n\nfor i, col in enumerate(columns_to_plot):\n    \n    # Sélectionner les données pour la colonne spécifique\n    data = communities_and_crime.loc[communities_and_crime['state'].isin(top_10_states), ['state', col]]\n    data = data.sort_values(by='state')\n    \n    # Créer le graphique à barres\n    ax = axs[i // 2, i % 2]\n    sns.barplot(x='state', y=col, data=data, palette='plasma', ax=ax)\n    ax.set_title(col)\n    ax.set_xlabel('State')\n    ax.set_ylabel('Value')\n\n\n# Afficher les graphiques\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:02.518265Z","iopub.execute_input":"2024-06-05T22:25:02.518663Z","iopub.status.idle":"2024-06-05T22:25:04.124767Z","shell.execute_reply.started":"2024-06-05T22:25:02.518632Z","shell.execute_reply":"2024-06-05T22:25:04.123486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> D'après les résultats de ces graphiques, nous remarquons que les facteurs démographiques majeurs de la criminalité violente élevée dans ces états sont :  **la jeunesse** et **le nombre élevé de personnes dans un foyer**\n>\n> De même, on voit que ces états n'ont pas un grand nombre de personnes vivant dans des zones urbaines (mise à part l'état 11), ce qui peut suugérer que ces villes sont principalement rurales et de petit nombre de population totale.\n>\n> En plus, le ratio de diversité ethnique reste tout de même considérable mais peu comparé aux taux généraux aux Etats-Unis , avec des pourcentages assez rapprochés entre ces états, ce qui peut refléter également des problèmes d'intégration. \n\n","metadata":{}},{"cell_type":"markdown","source":"### B. Caractéristiques économiques :\n___\n\nAprès une bonne analyse des colonnes du tableau, nous avons pu identifier ces attributs qui reflètent l'aspect économique des habitants :\n\n\n#### REVENUES\n\n* medIncome: Le revenu médian des foyers dans la communauté.\n* pctWWage: Le pourcentage de ménages ayant un revenu salarial en 1989.\n* pctWFarmSelf: Le pourcentage de ménages ayant un revenu d'exploitation agricole ou d'auto-emploi en 1989.\n* pctWInvInc: Le pourcentage de ménages ayant un revenu d'investissement ou de location en 1989.\n* pctWSocSec: Le pourcentage de ménages ayant un revenu de sécurité sociale en 1989.\n* pctWPubAsst: Le pourcentage de ménages ayant une aide publique en 1989.\n* pctWRetire: Le pourcentage de ménages ayant un revenu de retraite en 1989.\n* medFamInc: Le revenu médian des familles (différent du revenu des ménages pour les ménages non familiaux).\n* perCapInc: Le revenu par habitant.\n* whitePerCap: Le revenu par habitant pour les caucasiens.\n* blackPerCap: Le revenu par habitant pour les afro-américains.\n* indianPerCap: Le revenu par habitant pour les amérindiens.\n* AsianPerCap: Le revenu par habitant pour les personnes d'origine asiatique.\n* OtherPerCap: Le revenu par habitant pour les personnes d'autres origines.\n* HispPerCap: Le revenu par habitant pour les personnes d'origine hispanique.\n\n#### PAUVRETE\n\n* NumUnderPov: Le nombre de personnes sous le seuil de pauvreté.\n* PctPopUnderPov: Le pourcentage de personnes sous le seuil de pauvreté.\n\n#### EMPLOI\n\n* PctUnemployed: Le pourcentage de personnes de 16 ans et plus, dans la population active, et au chômage.\n* PctEmploy: Le pourcentage de personnes de 16 ans et plus employées.\n* PctEmplManu: Le pourcentage de personnes de 16 ans et plus employées dans la fabrication.\n* PctEmplProfServ: Le pourcentage de personnes de 16 ans et plus employées dans les services professionnels.\n* PctOccupManu: Le pourcentage de personnes de 16 ans et plus employées dans la fabrication.\n* PctOccupMgmtProf: Le pourcentage de personnes de 16 ans et plus employées dans la gestion ou les professions libérales.\n\n---\nEn vue du nombre important de ces caractéristiques, nous allons procéder au *Feature Engineering* pour essayer de créer des features plus simples et facile à utiliser.\n\nVoici donc quelques nouvelles features que l'on va créer :\n___\nRevenus agrégés :\n\n> **TotalIncome**: Le revenu total agrégé, combinant les revenus médians des ménages, des familles et par habitant.\n>\n> **PctLowIncome**: Le pourcentage de personnes vivant avec un revenu inférieur à un certain seuil basé sur les différentes mesures de revenu.\n\n___\nPauvreté et emploi :\n\n\n> **PovertyEmploymentRatio**: Le ratio entre le pourcentage de personnes sous le seuil de pauvreté et le pourcentage total d'emplois, donnant un aperçu de l'ampleur de la pauvreté relative au niveau d'emploi dans la communauté.\n>\n> **UnemploymentRate**: Le taux de chômage, indiquant la proportion de la population active sans emploi.\n","metadata":{}},{"cell_type":"code","source":"# Création des nouvelles features\n\n# Revenus agrégés\n# The average family in the USA is consisted of 3 persons => communities_and_crime['perCapInc']*3\ncommunities_and_crime['TotalFamIncome'] = (communities_and_crime['medIncome'] + communities_and_crime['medFamInc'] + communities_and_crime['perCapInc']*3)/3\ncommunities_and_crime['PctLowIncome'] = (communities_and_crime['NumUnderPov'] / communities_and_crime['population'])\n\n# Pauvreté et emploi\ncommunities_and_crime['PovertyEmploymentRatio'] = (communities_and_crime['PctPopUnderPov'] / communities_and_crime['PctEmploy'])\ncommunities_and_crime['UnemploymentRate'] = communities_and_crime['PctUnemployed']\n\n# Afficher les premières lignes du tableau pour vérifier les nouvelles colonnes\nprint(communities_and_crime[['TotalFamIncome', 'PctLowIncome', 'PovertyEmploymentRatio', 'UnemploymentRate']].head())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:04.126970Z","iopub.execute_input":"2024-06-05T22:25:04.127462Z","iopub.status.idle":"2024-06-05T22:25:04.142641Z","shell.execute_reply.started":"2024-06-05T22:25:04.127423Z","shell.execute_reply":"2024-06-05T22:25:04.141629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Ignorer les warnings de type RuntimeWarning liés au valeurs NaN\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:04.613807Z","iopub.execute_input":"2024-06-05T22:25:04.614199Z","iopub.status.idle":"2024-06-05T22:25:04.620195Z","shell.execute_reply.started":"2024-06-05T22:25:04.614172Z","shell.execute_reply":"2024-06-05T22:25:04.619013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sélectionner les colonnes à afficher\ncolumns_to_plot = ['TotalFamIncome', 'PctLowIncome', 'PovertyEmploymentRatio', 'UnemploymentRate']\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 6))\n\nfor i, col in enumerate(columns_to_plot):\n    \n    # Sélectionner les données pour la colonne spécifique\n    data = communities_and_crime.loc[communities_and_crime['state'].isin(top_10_states), ['state', col]]\n    data = data.sort_values(by='state')\n    \n    # Créer le graphique à barres\n    ax = axs[i // 2, i % 2]\n    sns.barplot(x='state', y=col, data=data, palette='mako', ax=ax)\n    ax.set_title(col)\n    ax.set_xlabel('State')\n    ax.set_ylabel('Value')\n\n\n# Afficher les graphiques\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:04.975811Z","iopub.execute_input":"2024-06-05T22:25:04.976248Z","iopub.status.idle":"2024-06-05T22:25:06.857048Z","shell.execute_reply.started":"2024-06-05T22:25:04.976215Z","shell.execute_reply":"2024-06-05T22:25:06.855957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> - Les graphiques ci-dessus révèlent une tendance préoccupante : les états avec des taux de criminalité les plus élevés affichent généralement une forte proportion de personnes vivant sous le seuil de pauvreté.\n> De même, on peut facilement remarquer que les revenus familiaux totaux dans ces états sont pour la majorité en dessous de la moyenne.\n> \n> - De plus, le taux de chômage y est alarmant, touchant près de la moitié de la population.\n> \n> Cependant, le ratio entre le pourcentage de personnes vivant dans la pauvreté et le pourcentage total de travailleurs nous mène à deux conclusions : \n>\n> - Le première, c'est que dans certains états, ce ration est assez élévé, ce qui serait fortement justifié par un taux de chommage considérable, ce qui induit à des taux de povreté très significatifs et donc à plus d'exposition à commetre des crimes violents comme les vols et les aggressions. \n>\n> - La deuxième, c'est que dans d'autres états le ration est moins de 1, ce qui signifie qu'il y a plus de travailleurs que de personnes pauvres. Cela donc suggère que même ceux qui sont employés pourraient ne pas gagner suffisamment pour subvenir à leurs besoins face au coût de la vie.","metadata":{}},{"cell_type":"markdown","source":"### C. Caractéristiques sociales :\n___\n\nAprès une bonne analyse des colonnes du tableau, nous avons pu identifier ces attributs qui reflètent l'aspect social des habitants :\n\nCaractéristiques sociales :\n\n#### NIVEAU D'ETUDE\n\n* PctLess9thGrade: Le pourcentage de personnes de 25 ans et plus ayant moins qu'une éducation de 9e année.\n* PctNotHSGrad: Le pourcentage de personnes de 25 ans et plus qui ne sont pas diplômées de l'école secondaire.\n* PctBSorMore: Le pourcentage de personnes de 25 ans et plus avec un diplôme de baccalauréat ou plus.\n\n#### SITUATION SOCIALE\n\n* MalePctDivorce: Le pourcentage d'hommes divorcés.\n* MalePctNevMarr: Le pourcentage d'hommes jamais mariés.\n* FemalePctDiv: Le pourcentage de femmes divorcées.\n* TotalPctDiv: Le pourcentage de la population divorcée.\n* PersPerFam: Le nombre moyen de personnes par famille.\n* PctFam2Par: Le pourcentage de familles (avec enfants) dirigées par deux parents.\n* PctKids2Par: Le pourcentage d'enfants dans des foyers familiaux avec deux parents.\n* PctYoungKids2Par: Le pourcentage d'enfants de 4 ans et moins dans des foyers avec deux parents.\n* PctTeen2Par: Le pourcentage d'enfants de 12 à 17 ans dans des foyers avec deux parents.\n* PctWorkMomYoungKids: Le pourcentage de mères d'enfants de 6 ans et moins dans la population active.\n* PctWorkMom: Le pourcentage de mères d'enfants de moins de 18 ans dans la population active.\n\n---\nEn vue du nombre important de ces caractéristiques, nous allons procéder au *Feature Engineering* pour essayer de créer des features plus simples et facile à utiliser.\n\nVoici donc quelques nouvelles features que l'on va créer :\n___\n\nEducation et emploi :\n\n> **EducatedEmployed**: Le pourcentage de personnes ayant au moins un diplôme d'études secondaires et étant employées.\n>\n> **ManuEmploymentRatio**: Le ratio entre le pourcentage d'emplois dans le secteur \"*manufacturier*\" et le pourcentage total d'emplois, indiquant l'importance relative de ce secteur dans l'emploi local.\n>\n> **ProfServEmployment**: Le pourcentage d'emplois dans les \"*services professionnels*\" par rapport à l'ensemble des emplois, reflétant la part de l'emploi dans ce secteur.\n\n___\nSituation sociale et familiale :\n\n\n> **DivorceRate**: Le taux de divorce, calculé en combinant les pourcentages de personnes divorcées.\n>\n> **FamilyStructure**: Une variable catégorielle indiquant la structure familiale dominante dans la communauté (monoparentale, biparentale).\n>\n> **WorkingMothers**: Le pourcentage de mères de jeunes enfants (moins de 6 ans) travaillant par rapport à l'ensemble des mères actives, mettant en évidence la participation des mères au marché du travail malgré les responsabilités familiales.\n","metadata":{}},{"cell_type":"code","source":"# Création des nouvelles features\n\n# Education et emploi\ncommunities_and_crime['EducatedEmployed'] = (100 - communities_and_crime['PctNotHSGrad']) * (communities_and_crime['PctEmploy'] / 100)\ncommunities_and_crime['ManuEmploymentRatio'] = communities_and_crime['PctEmplManu'] / (1 - communities_and_crime['PctUnemployed'])\ncommunities_and_crime['ProfServEmployment'] = (communities_and_crime['PctEmplProfServ'] / (100 - communities_and_crime['PctUnemployed'])) * 100\n\n# Situation sociale et familiale\ncommunities_and_crime['DivorceRate'] = (communities_and_crime['MalePctDivorce'] + communities_and_crime['FemalePctDiv'] + communities_and_crime['TotalPctDiv']) / 3\ncommunities_and_crime['FamilyStructure'] = communities_and_crime.apply(\n    lambda row: 'Biparentale' if row['PctFam2Par'] > 50 else 'Monoparentale', axis=1)\ncommunities_and_crime['WorkingMothers'] = (communities_and_crime['PctWorkMom'] + communities_and_crime['PctWorkMomYoungKids'])/2\n\nprint(communities_and_crime[['EducatedEmployed', 'ManuEmploymentRatio', 'ProfServEmployment', 'DivorceRate', 'FamilyStructure', 'WorkingMothers']].head())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:06.859436Z","iopub.execute_input":"2024-06-05T22:25:06.859867Z","iopub.status.idle":"2024-06-05T22:25:06.909999Z","shell.execute_reply.started":"2024-06-05T22:25:06.859829Z","shell.execute_reply":"2024-06-05T22:25:06.908587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sélectionner les colonnes à afficher\ncolumns_to_plot = ['EducatedEmployed', 'ManuEmploymentRatio', 'ProfServEmployment', 'DivorceRate', 'WorkingMothers']\n\nfig, axs = plt.subplots(2, 3, figsize=(18, 10))\n\nfor i, col in enumerate(columns_to_plot):\n    \n    # Sélectionner les données pour la colonne spécifique\n    data = communities_and_crime.loc[communities_and_crime['state'].isin(top_10_states), ['state', col]]\n    data = data.sort_values(by='state')\n    \n    # Créer le graphique à barres\n    ax = axs[i // 3, i % 3]\n    sns.barplot(x='state', y=col, data=data, palette='cividis', ax=ax)\n    ax.set_title(col)\n    ax.set_xlabel('State')\n    ax.set_ylabel('Value')\n\n# Supprimer les axes inutilisés\nfor j in range(5, len(axs.flatten())):\n    fig.delaxes(axs[j // 3, j % 3])\n    \n# Afficher les graphiques\nplt.tight_layout()\nplt.show()\n\n\n\n\ndata = communities_and_crime.loc[communities_and_crime['state'].isin(top_10_states), ['state', 'FamilyStructure']]\ndata = data.sort_values(by='state')\n\n# Compter le nombre de chaque valeur dans la colonne \"FamilyStructure\"\nvalue_counts = data['FamilyStructure'].value_counts()\n\n# Créer le graphique circulaire avec les comptages\nplt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90, colors=plt.cm.cividis.colors)\nplt.title('FamilyStructure')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:06.911378Z","iopub.execute_input":"2024-06-05T22:25:06.911827Z","iopub.status.idle":"2024-06-05T22:25:09.175920Z","shell.execute_reply.started":"2024-06-05T22:25:06.911787Z","shell.execute_reply":"2024-06-05T22:25:09.174624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Dans le domaine de l'éducation, les graphiques montrent un faible nombre de jeunes diplômés et employés dans ces villes. De plus, les métiers ne nécessitant pas de diplômes élevés sont sous-représentés, rendant l'accès à l'emploi difficile pour beaucoup. Cette situation peut pousser certains à commettre des crimes pour survivre.\n> \n> En examinant le contexte familial, on observe une forte corrélation avec plusieurs indicateurs. Dans ces villes, les taux de divorce sont élevés, avec plus de la moitié des couples mariés qui se séparent. \n>\n> Cela entraîne une prévalence de familles monoparentales, où l'éducation des enfants devient une tâche ardue. De plus, le pourcentage de mères travaillant est élevé, ce qui suggère que dans la majorité des familles monoparentales, c'est la mère qui est le parent responsable. Elle doit jongler entre l'éducation des enfants, les tâches ménagères et un emploi souvent mal rémunéré. \n>\n> Ce manque de temps et de ressources peut conduire à une éducation insuffisante des enfants, contribuant ainsi à une augmentation du taux de criminalité dans ces villes.","metadata":{"execution":{"iopub.status.busy":"2024-06-03T22:14:10.089719Z","iopub.execute_input":"2024-06-03T22:14:10.090260Z","iopub.status.idle":"2024-06-03T22:14:10.099266Z","shell.execute_reply.started":"2024-06-03T22:14:10.090200Z","shell.execute_reply":"2024-06-03T22:14:10.097376Z"}}},{"cell_type":"markdown","source":"# II - Application des algorithmes d'apprentissage supervisé sur les données : Prédiction du taux de crimes violents","metadata":{}},{"cell_type":"markdown","source":"\nPour notre tâche de prédiction de la colonne **ViolentCrimesPerPop** en utilisant des algorithmes d'apprentissage supervisé, nous allons considérer plusieurs algorithmes adaptés à une tâche de régression, étant donné que nous prédisons une valeur numérique. \n\nVoici les algorithmes d'apprentissage supervisé sur lesquels on va entrainer nos modèles :\n\n1. *Régression linéaire*\n\n2. *Arbres de décision*\n\n3. *Forêts aléatoires*\n\n4. *Algorithme K-NN*\n\n5. *Algorithme de Support Vector Machine (SVM)*","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:09.178394Z","iopub.execute_input":"2024-06-05T22:25:09.179215Z","iopub.status.idle":"2024-06-05T22:25:09.185271Z","shell.execute_reply.started":"2024-06-05T22:25:09.179170Z","shell.execute_reply":"2024-06-05T22:25:09.183817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___\n### **Mean Squarred Error**\n> L'erreur quadratique moyenne (MSE, pour Mean Squared Error) est une mesure de la qualité d'un estimateur, en particulier dans les modèles de régression. Elle est calculée comme la moyenne des carrés des écarts entre les valeurs observées (réelles) et les valeurs prédites par le modèle. Plus la MSE est faible, meilleur est le modèle.\n___","metadata":{}},{"cell_type":"markdown","source":"## A. Selon les caractéristiques économiques :\n\nOn va appliquer les algorithmes de **Régression linéaire** et de **Support Vector Machine Regression (SVM-R)** en prenant en compte plusieurs features : \n* **TotalFamIncome:** Le revenu total agrégé, combinant les revenus médians des ménages, des familles et par 3 habitants.\n* **UnemploymentRate:** Le taux de chômage, indiquant la proportion de la population active sans emploi.\n","metadata":{}},{"cell_type":"markdown","source":"___\n## Protocole expérimental : \nSéparation des données en deux parties : **80%** pour l'apprentissage et **20%** pour la validation.","metadata":{}},{"cell_type":"code","source":"# X : Caractéristiques économiques\nX = communities_and_crime[['TotalFamIncome', 'UnemploymentRate']]  \n# y : Taux de crimes violents par population\ny = communities_and_crime['ViolentCrimesPerPop']","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:09.186818Z","iopub.execute_input":"2024-06-05T22:25:09.187870Z","iopub.status.idle":"2024-06-05T22:25:09.199698Z","shell.execute_reply.started":"2024-06-05T22:25:09.187826Z","shell.execute_reply":"2024-06-05T22:25:09.198709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:09.359553Z","iopub.execute_input":"2024-06-05T22:25:09.359945Z","iopub.status.idle":"2024-06-05T22:25:09.368257Z","shell.execute_reply.started":"2024-06-05T22:25:09.359914Z","shell.execute_reply":"2024-06-05T22:25:09.367136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"### **1. Algorithme de Regression linéaire :**\n\n> C'est le choix de base pour les problèmes de régression, notamment lorsque les relations entre les caractéristiques et la variable cible sont linéaires.\n> Simple à comprendre et à interpréter, ce qui en fait un bon point de départ.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\n# Initialiser le modèle de régression linéaire\nlinear_reg = LinearRegression()\n\n# Entraîner le modèle sur les données d'entraînement\nlinear_reg.fit(X_train, y_train)\n\n# Faire des prédictions sur les données de test\ny_pred = linear_reg.predict(X_test)\n\n# Calculer l'erreur quadratique moyenne (MSE)\nmse = mean_squared_error(y_test, y_pred)\n\n# Effectuer une validation croisée\ncv_scores = cross_val_score(linear_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\nmse_cv = -cv_scores.mean()\nprint(\"Mean Squared Error (Cross-Validation):\", mse_cv)\nprint(\"Mean Squared Error (Linear Regression):\", mse)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:10.973176Z","iopub.execute_input":"2024-06-05T22:25:10.973564Z","iopub.status.idle":"2024-06-05T22:25:11.017277Z","shell.execute_reply.started":"2024-06-05T22:25:10.973535Z","shell.execute_reply":"2024-06-05T22:25:11.016111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> - La validation croisée n'a pas permis de réduire le MSE par rapport aux résultats de la régression linéaire classique \n> \n> - Cependant, ça reste une bonne pratique pour éviter l'**overfitting**","metadata":{}},{"cell_type":"markdown","source":"#### **Diagramme de dispersion avec ligne de régression**\n___\n> C'est une visualisation qui permet d'évaluer la précision de la prédiction d'un modèle de régression.","metadata":{}},{"cell_type":"code","source":"# Calculer la distance entre les valeurs réelles et les prédictions du modèle\ndistances = np.abs(y_test - y_pred)\n\n# Définir la colormap et normaliser les distances\nnorm = plt.Normalize(distances.min(), distances.max())\ncmap = plt.cm.viridis\n\n# Tracer le diagramme de dispersion avec une couleur dégradée basée sur la distance à la ligne de régression\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred_linear, c=distances, cmap=cmap, norm=norm)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nplt.colorbar(label='Distance à la ligne de régression')\nplt.xlabel('Valeurs réelles')\nplt.ylabel('Prédictions du modèle')\nplt.title('Diagramme de dispersion')\nplt.text(y_test.min(), y_test.max(), 'MSE: {:.2f}'.format(mse_linear), verticalalignment='top')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:12.307632Z","iopub.execute_input":"2024-06-05T22:25:12.308150Z","iopub.status.idle":"2024-06-05T22:25:12.780008Z","shell.execute_reply.started":"2024-06-05T22:25:12.308112Z","shell.execute_reply":"2024-06-05T22:25:12.778563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2. Algorithme de Support Vector Machine Regression (SVM-R) :**\n> Algorithme qui trouve l'hyperplan optimal dans un espace de grande dimension pour séparer les données en différentes classes. Ils sont efficaces dans les espaces de grande dimension et peuvent gérer des données non linéaires en utilisant des noyaux.","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\n# Normaliser les données\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialiser le modèle SVM pour la régression\nsvm_reg = SVR()\n\n# Définir la grille des hyperparamètres à optimiser\nparam_grid = {\n    'kernel': ['linear', 'rbf', 'poly'],\n    'C': [0.1, 1, 10],\n    'gamma': ['scale', 'auto']\n}\n\n# Utiliser la recherche sur grille pour trouver les meilleurs hyperparamètres\ngrid_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\ngrid_search.fit(X_train_scaled, y_train)\n\n# Afficher les meilleurs hyperparamètres\nprint(\"Meilleurs hyperparamètres:\", grid_search.best_params_)\n\n# Utiliser le modèle avec les meilleurs hyperparamètres pour faire des prédictions\nbest_svm_reg = grid_search.best_estimator_\ny_pred_svm = best_svm_reg.predict(X_test_scaled)\n\n# Calculer l'erreur quadratique moyenne (MSE) pour le SVM\nmse_svm = mean_squared_error(y_test, y_pred_svm)\nprint(\"Mean Squared Error (SVM):\", mse_svm)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:13.857881Z","iopub.execute_input":"2024-06-05T22:25:13.858708Z","iopub.status.idle":"2024-06-05T22:25:42.303118Z","shell.execute_reply.started":"2024-06-05T22:25:13.858667Z","shell.execute_reply":"2024-06-05T22:25:42.301820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Un MSE de 0.0414 est assez bas, ce qui indique que le modèle SVM est capable de faire des prédictions assez précises sur le nombre de crimes violents par population.\n>\n> Cela signifie que les prédictions du modèle sont en moyenne assez proches des valeurs réelles du nombre de crimes violents par population dans votre ensemble de test.\n>\n> Globalement, un MSE aussi bas suggère que le modèle SVM performe bien pour ce problème de prédiction.","metadata":{}},{"cell_type":"markdown","source":"#### **Courbe d'apprentissage**\n___\n> C'est une visualisation qui montre comment les performances d'un modèle évoluent en fonction de la taille de l'ensemble d'entraînement. Elle permet de comprendre comment le modèle se comporte lorsque la quantité de données d'entraînement varie.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n\n# Définir les tailles d'ensemble d'entraînement à tester\ntrain_sizes = [0.1, 0.3, 0.5, 0.7, 0.9]\n\n# Calculer la courbe d'apprentissage\ntrain_sizes_abs, train_scores, test_scores = learning_curve(\n    estimator=svm_reg,\n    X=X_train,\n    y=y_train,\n    train_sizes=train_sizes,\n    cv=5,  # Nombre de plis pour la validation croisée\n    scoring='neg_mean_squared_error',  # Métrique à utiliser\n    n_jobs=-1  # Utiliser tous les coeurs CPU disponibles\n)\n\n# Calculer les scores moyens et les écarts-types\ntrain_scores_mean = -np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = -np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\n# Tracer la courbe d'apprentissage\nplt.figure(figsize=(10, 6))\nplt.plot(train_sizes_abs, train_scores_mean, 'o-', color='r', label='Score d\\'entraînement')\nplt.plot(train_sizes_abs, test_scores_mean, 'o-', color='g', label='Score de validation')\nplt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\nplt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\nplt.xlabel('Taille de l\\'ensemble d\\'entraînement')\nplt.ylabel('MSE')\nplt.title('Courbe d\\'Apprentissage SVM-R')\nplt.legend(loc='best')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:42.305715Z","iopub.execute_input":"2024-06-05T22:25:42.306125Z","iopub.status.idle":"2024-06-05T22:25:45.425219Z","shell.execute_reply.started":"2024-06-05T22:25:42.306083Z","shell.execute_reply":"2024-06-05T22:25:45.423281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Ce graphique permet de comprendre à partir d'une taille de 400 exemple d'entrainement, la différence entre le score de celui-ci et le score de validation est assez minimale.\n","metadata":{}},{"cell_type":"markdown","source":"___\n## B. Selon les caractéristiques sociales :\n\nOn va appliquer les algorithmes de **Régression linéaire**, d'**Arbres de décision** et de **Forêts Aléatoires**  en prenant en compte deux features : \n*     **DivorceRate**: Le taux de divorce, calculé en combinant les pourcentages de personnes divorcées.\n*     **EducatedEmployed**: Le pourcentage de personnes ayant au moins un diplôme d'études secondaires et étant employées.\n","metadata":{}},{"cell_type":"markdown","source":"___\n## Protocole expérimental : \nSéparation des données en deux parties : **80%** pour l'apprentissage et **20%** pour la validation.","metadata":{}},{"cell_type":"code","source":"# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(communities_and_crime[['DivorceRate', 'EducatedEmployed']], communities_and_crime['ViolentCrimesPerPop'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:45.427015Z","iopub.execute_input":"2024-06-05T22:25:45.427432Z","iopub.status.idle":"2024-06-05T22:25:45.440229Z","shell.execute_reply.started":"2024-06-05T22:25:45.427393Z","shell.execute_reply":"2024-06-05T22:25:45.438549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"### **1. Algorithme de Regression linéaire :**","metadata":{}},{"cell_type":"code","source":"# Initialiser le modèle\nlinear_reg = LinearRegression()\n\n# Entraîner le modèle\nlinear_reg.fit(X_train, y_train)\n\n# Faire des prédictions sur l'ensemble de test\ny_pred_linear = linear_reg.predict(X_test)\n\n# Évaluer les performances du modèle\nmse_linear = mean_squared_error(y_test, y_pred_linear)\n\n# Effectuer une validation croisée\nscores = cross_val_score(linear_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n# scoring='neg_mean_squared_error' pour utiliser l'erreur quadratique moyenne (MSE)\n\n# Calculer le score moyen\nmean_score = np.mean(scores)\n# Afficher le résultat\nprint(\"Mean Squared Error (Cross-validated Linear Regression):\", -mean_score)\n\n# Afficher le taux d'erreur de cet algorithme\nprint(\"Mean Squared Error (Linear Regression):\", mse_linear)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:45.443341Z","iopub.execute_input":"2024-06-05T22:25:45.443735Z","iopub.status.idle":"2024-06-05T22:25:45.493486Z","shell.execute_reply.started":"2024-06-05T22:25:45.443695Z","shell.execute_reply":"2024-06-05T22:25:45.491323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Diagramme de dispersion avec ligne de régression**\n___","metadata":{}},{"cell_type":"code","source":"# Calculer la distance entre les valeurs réelles et les prédictions du modèle\ndistances = np.abs(y_test - y_pred_linear)\n\n# Définir la colormap et normaliser les distances\nnorm = plt.Normalize(distances.min(), distances.max())\ncmap = plt.cm.cividis\n\n# Tracer le diagramme de dispersion avec une couleur dégradée basée sur la distance à la ligne de régression\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred_linear, c=distances, cmap=cmap, norm=norm)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nplt.colorbar(label='Distance à la ligne de régression')\nplt.xlabel('Valeurs réelles')\nplt.ylabel('Prédictions du modèle')\nplt.title('Diagramme de dispersion')\nplt.text(y_test.min(), y_test.max(), 'MSE: {:.2f}'.format(mse_linear), verticalalignment='top')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:25:45.495916Z","iopub.execute_input":"2024-06-05T22:25:45.496607Z","iopub.status.idle":"2024-06-05T22:25:45.997550Z","shell.execute_reply.started":"2024-06-05T22:25:45.496548Z","shell.execute_reply":"2024-06-05T22:25:45.996123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2. Algorithme d'Arbres de Décision (Regression):**\n>Flexibles et peuvent capturer des relations non linéaires entre les caractéristiques et la variable cible.\n>\n>Peuvent gérer différents types de données et sont relativement robustes au bruit et aux valeurs aberrantes.","metadata":{}},{"cell_type":"markdown","source":"#### **Variation des performances avec la profondeur de l'arbre : Trouvons la profondeur de l'arbre optimale !**\n___","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n# Tracer les performances en fonction de la profondeur de l'arbre\ndepths = range(1, 21)\nmse_values = []\n\nfor depth in depths:\n    model = DecisionTreeRegressor(max_depth=depth)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    mse_values.append(mse)\n\nplt.figure(figsize=(8, 6))\nplt.plot(depths, mse_values, marker='o')\nplt.xlabel('Profondeur de l\\'arbre')\nplt.ylabel('Mean Squared Error')\nplt.title('Variation des performances avec la profondeur de l\\'arbre')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:26:05.275852Z","iopub.execute_input":"2024-06-05T22:26:05.276279Z","iopub.status.idle":"2024-06-05T22:26:05.699305Z","shell.execute_reply.started":"2024-06-05T22:26:05.276247Z","shell.execute_reply":"2024-06-05T22:26:05.698012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Avec ce graphe, on a pu trouver que le meilleur paramètre de profondeur pour la performance optimale de ce modèle serait d'environ **3**.","metadata":{}},{"cell_type":"code","source":"# Initialiser le modèle\ndecision_tree_reg = DecisionTreeRegressor(max_depth=3)\n\n# Entraîner le modèle\ndecision_tree_reg.fit(X_train, y_train)\n\n# Faire des prédictions sur l'ensemble de test\ny_pred_tree = decision_tree_reg.predict(X_test)\n\n# Évaluer les performances du modèle\nmse_tree = mean_squared_error(y_test, y_pred_tree)\n\n# Afficher le taux d'erreur de cet algorithme\nprint(\"Mean Squared Error (Decision Tree):\", mse_tree)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:26:09.082612Z","iopub.execute_input":"2024-06-05T22:26:09.083009Z","iopub.status.idle":"2024-06-05T22:26:09.097768Z","shell.execute_reply.started":"2024-06-05T22:26:09.082980Z","shell.execute_reply":"2024-06-05T22:26:09.096359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Courbe d'apprentissage**\n___","metadata":{}},{"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(decision_tree_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n\n# Calculer les scores moyens et les écarts-types\ntrain_scores_mean = -np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = -np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(train_sizes, train_scores_mean, 'o-', color='c', label='Erreur d\\'entraînement')\nplt.plot(train_sizes, test_scores_mean, 'o-', color='y', label='Erreur de validation')\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='c')\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='y')\nplt.xlabel('Taille de l\\'ensemble de formation')\nplt.ylabel('Erreur Quadratique Moyenne (MSE)')\nplt.title('Courbe d\\'Apprentissage')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:26:15.211829Z","iopub.execute_input":"2024-06-05T22:26:15.212253Z","iopub.status.idle":"2024-06-05T22:26:15.704867Z","shell.execute_reply.started":"2024-06-05T22:26:15.212221Z","shell.execute_reply":"2024-06-05T22:26:15.703440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> On remarque donc que le meilleur nombre d'exemples pour entrainer cet algorithme serait à partir de **700**.","metadata":{}},{"cell_type":"markdown","source":"### \n### **3. Algorithme de Fôrets aléatoires (Régression) :**\n  > Ensembles d'arbres de décision qui réduisent le surajustement (**overfitting**) et améliorent la généralisation en agrégeant les prédictions de plusieurs arbres.\n  >\n  > Robustes et offrent généralement de bonnes performances sans nécessiter beaucoup de réglages d'hyperparamètres.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Initialiser le modèle\nrandom_forest_reg = RandomForestRegressor()\n\n# Entraîner le modèle\nrandom_forest_reg.fit(X_train, y_train)\n\n# Faire des prédictions sur l'ensemble de test\ny_pred_forest = random_forest_reg.predict(X_test)\n\n# Évaluer les performances du modèle\nmse_forest = mean_squared_error(y_test, y_pred_forest)\n\n# Afficher le taux d'erreur de cet algorithme\nprint(\"Mean Squared Error (Random Forest):\", mse_forest)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:28:13.324264Z","iopub.execute_input":"2024-06-05T22:28:13.324689Z","iopub.status.idle":"2024-06-05T22:28:13.778128Z","shell.execute_reply.started":"2024-06-05T22:28:13.324657Z","shell.execute_reply":"2024-06-05T22:28:13.776853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Courbe d'apprentissage**\n___","metadata":{}},{"cell_type":"code","source":"# Définir les tailles d'ensemble d'entraînement à tester\ntrain_sizes = np.linspace(0.1, 1.0, 10)\n\n# Calculer les scores d'apprentissage et de validation\ntrain_sizes_abs, train_scores, test_scores = learning_curve(random_forest_reg, X_train, y_train, train_sizes=train_sizes, cv=5, scoring='neg_mean_squared_error')\n\n# Calculer les scores moyens et les écarts-types\ntrain_scores_mean = -np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = -np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\n# Tracer la courbe d'apprentissage\nplt.figure(figsize=(10, 6))\nplt.plot(train_sizes_abs, train_scores_mean, 'o-', color='r', label='Erreur d\\'entraînement')\nplt.plot(train_sizes_abs, test_scores_mean, 'o-', color='g', label='Erreur de validation')\nplt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\nplt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\nplt.xlabel('Taille de l\\'ensemble d\\'entraînement')\nplt.ylabel('Erreur Quadratique Moyenne')\nplt.title('Courbe d\\'Apprentissage')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:29:30.539920Z","iopub.execute_input":"2024-06-05T22:29:30.540351Z","iopub.status.idle":"2024-06-05T22:29:44.785588Z","shell.execute_reply.started":"2024-06-05T22:29:30.540319Z","shell.execute_reply":"2024-06-05T22:29:44.784465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Avec ce graphe, vu que les courbes d'erreur d'entraînement et de validation convergent, on pense que cela peut indiquer que le modèle est trop complexe pour la quantité de données disponible, ou que le modèle n'a pas la capacité d'apprendre la relation entre les caractéristiques et la cible.\n> ","metadata":{}},{"cell_type":"markdown","source":"\n## C. Faisant le bilan de prédiction avec les différentes caractéristiques !\n___\n On va appliquer l'algorithme de **Régression linéaire** et de **K-NN** en prenant en compte plusieurs features : \n *     **TotalFamIncome**\n *     **UnemploymentRate**\n *     **DivorceRate**\n *     **EducatedEmployed**\n *     **youthIndex**\n *     **ethnicDiversityRatio**","metadata":{}},{"cell_type":"markdown","source":"___\n## Protocole expérimental : \nSéparation des données en deux parties : **80%** pour l'apprentissage et **20%** pour la validation.","metadata":{}},{"cell_type":"code","source":"# X : Caractéristiques économiques\nX = communities_and_crime[['TotalFamIncome', 'UnemploymentRate','DivorceRate','EducatedEmployed','youthIndex','ethnicDiversityRatio']]  \n# y : Nombre de crimes violents par population\ny = communities_and_crime['ViolentCrimesPerPop']","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:37:25.533123Z","iopub.execute_input":"2024-06-05T22:37:25.533513Z","iopub.status.idle":"2024-06-05T22:37:25.540640Z","shell.execute_reply.started":"2024-06-05T22:37:25.533483Z","shell.execute_reply":"2024-06-05T22:37:25.539348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:37:27.594606Z","iopub.execute_input":"2024-06-05T22:37:27.595038Z","iopub.status.idle":"2024-06-05T22:37:27.604462Z","shell.execute_reply.started":"2024-06-05T22:37:27.595004Z","shell.execute_reply":"2024-06-05T22:37:27.603257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"### **1. Algorithme de Régression Linéaire :**","metadata":{}},{"cell_type":"code","source":"# Initialiser le modèle de régression linéaire\nlinear_reg = LinearRegression()\n\n# Entraîner le modèle sur les données d'entraînement\nlinear_reg.fit(X_train, y_train)\n\n# Faire des prédictions sur les données de test\ny_pred = linear_reg.predict(X_test)\n\n# Calculer l'erreur quadratique moyenne (MSE)\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error (Linear Regression):\", mse)\n\n# Afficher les coefficients de régression\ncoefficients = pd.DataFrame(linear_reg.coef_, X.columns, columns=['Coefficient'])\nprint(coefficients)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:38:17.950029Z","iopub.execute_input":"2024-06-05T22:38:17.950517Z","iopub.status.idle":"2024-06-05T22:38:17.969873Z","shell.execute_reply.started":"2024-06-05T22:38:17.950480Z","shell.execute_reply":"2024-06-05T22:38:17.968576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Diagramme de dispersion avec ligne de régression**\n___","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred, c=y_test, cmap='viridis', alpha=0.5)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nplt.xlabel('Valeurs réelles')\nplt.ylabel('Prédictions')\nplt.title('Diagramme de dispersion des prédictions par rapport aux valeurs réelles')\nplt.colorbar(label='Distance à la ligne de régression')\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:39:27.369184Z","iopub.execute_input":"2024-06-05T22:39:27.369569Z","iopub.status.idle":"2024-06-05T22:39:27.783181Z","shell.execute_reply.started":"2024-06-05T22:39:27.369541Z","shell.execute_reply":"2024-06-05T22:39:27.782119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> On remarque que la dispersion au niveau des points par rapport à la droite est minime. \n>\n> C'est donc un algorithme assez performant.","metadata":{}},{"cell_type":"markdown","source":"#### **Courbe d'apprentissage**\n___","metadata":{}},{"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error')\n\n# Calculer les scores moyens et les écarts-types\ntrain_scores_mean = -train_scores.mean(axis=1)\ntrain_scores_std = train_scores.std(axis=1)\ntest_scores_mean = -test_scores.mean(axis=1)\ntest_scores_std = test_scores.std(axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Erreur d\\'entraînement')\nplt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Erreur de validation')\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\nplt.xlabel('Taille de l\\'ensemble de formation')\nplt.ylabel('Erreur Quadratique Moyenne')\nplt.title('Courbe d\\'Apprentissage')\nplt.legend(loc='best')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:40:57.605200Z","iopub.execute_input":"2024-06-05T22:40:57.605597Z","iopub.status.idle":"2024-06-05T22:40:58.256122Z","shell.execute_reply.started":"2024-06-05T22:40:57.605568Z","shell.execute_reply":"2024-06-05T22:40:58.254979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> La courbe d'apprentissage confirme notre constat antérieur, il y a une intersection entre les 2 courbes et on peut remarquer que c'est surtout à partir d'un échantillon de 1400 qu' on a un bon modèle","metadata":{}},{"cell_type":"markdown","source":"### **2. Algorithme de K-NN (Régression) :**","metadata":{}},{"cell_type":"markdown","source":"#### **Quelle valeur de K serait la plus optimale ?**\n___\n> On va appliquer l'algorithme de la validation croisée, pour ensuite utiliser la méthode du coude.","metadata":{}},{"cell_type":"code","source":"neighbors = list(range(1, 20))\ncv_scores = []\n\n# Effectuer une validation croisée pour chaque nombre de voisins\nfor k in neighbors:\n    knn = KNeighborsRegressor(n_neighbors=k)\n    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n    cv_scores.append(scores.mean())\n\n# Tracer la courbe de validation croisée\nplt.figure(figsize=(10, 6))\nplt.plot(neighbors, -np.array(cv_scores), marker='o')\nplt.xlabel('Nombre de voisins (k)')\nplt.ylabel('Erreur Quadratique Moyenne')\nplt.title('Courbe de validation croisée')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:50:09.404667Z","iopub.execute_input":"2024-06-05T22:50:09.405131Z","iopub.status.idle":"2024-06-05T22:50:10.383613Z","shell.execute_reply.started":"2024-06-05T22:50:09.405095Z","shell.execute_reply":"2024-06-05T22:50:10.382107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> La méthode du coude nous a permis de trouver le meilleur paramètre K pour notre K-NN afin d'avoir la meilleure performance possible dans le cas actuel.\n>\n> De ce fait, le K optimal ici serait K = 4.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialiser le modèle KNN\nknn = KNeighborsRegressor(n_neighbors=4)\n\n# Entraîner le modèle\nknn.fit(X_train_scaled, y_train)\n\n# Faire des prédictions sur l'ensemble de test\ny_pred = knn.predict(X_test_scaled)\n\n# Évaluer les performances du modèle\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error (KNN):\", mse)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:50:32.955906Z","iopub.execute_input":"2024-06-05T22:50:32.956709Z","iopub.status.idle":"2024-06-05T22:50:32.986001Z","shell.execute_reply.started":"2024-06-05T22:50:32.956643Z","shell.execute_reply":"2024-06-05T22:50:32.983467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Diagramme de dispersion avec ligne de régression**\n___","metadata":{}},{"cell_type":"code","source":"# Diagramme de dispersion des prédictions par rapport aux valeurs réelles\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred, c=y_test, cmap='viridis', alpha=0.5)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nplt.xlabel('Valeurs réelles')\nplt.ylabel('Prédictions')\nplt.title('Diagramme de dispersion des prédictions par rapport aux valeurs réelles')\nplt.legend()\nplt.colorbar(label='Distance à la ligne de régression')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:50:35.512076Z","iopub.execute_input":"2024-06-05T22:50:35.512494Z","iopub.status.idle":"2024-06-05T22:50:35.977894Z","shell.execute_reply.started":"2024-06-05T22:50:35.512460Z","shell.execute_reply":"2024-06-05T22:50:35.976299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Le résultat du mean square error ainsi que le diagramme de dispersion des prédictions nous permet de déduire que cet algorithme de régression est assez compatible à notre cas de figure et donne des résultats assez satisfaisants.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion \n___\n\nL'analyse des données sur la criminalité révèle que les facteurs économiques, éducatifs, sociaux et démographiques sont interconnectés et influencent significativement les taux de criminalité. \n\nDes revenus plus élevés et diversifiés, ainsi qu'une faible pauvreté et des taux de chômage bas, sont associés à des niveaux de criminalité plus faibles. \n\nL'éducation joue un rôle crucial, avec des états ayant un pourcentage élevé de diplômés du secondaire et des taux d'emploi élevés montrant des taux de criminalité plus bas. \n\nLes structures familiales stables et le soutien parental fort sont également liés à une réduction de la criminalité. \n\nDe plus, la diversité ethnique et le niveau d'urbanisation influencent les taux de criminalité, les zones urbaines présentant des dynamiques variées selon la composition ethnique et la densité de population. \n\n\nPour lutter contre la criminalité, il est recommandé d'investir dans l'éducation et l'emploi, de renforcer les structures familiales, de développer des politiques urbaines inclusives, et d'augmenter les aides publiques pour les populations vulnérables. \n\nUne approche holistique, intégrant ces mesures, est essentielle pour réduire efficacement les taux de criminalité en améliorant les conditions de vie et en soutenant les populations les plus vulnérables.","metadata":{}},{"cell_type":"markdown","source":"                               L3 DANT - Introduction à la Data Science - 2023/2024 ©","metadata":{}}]}
